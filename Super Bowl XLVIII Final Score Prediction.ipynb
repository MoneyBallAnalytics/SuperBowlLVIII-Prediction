{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926dc295",
   "metadata": {},
   "source": [
    "# Super Bowl XLVIII Final Score Prediction: SF: 26 | KC: 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f6d08",
   "metadata": {},
   "source": [
    "**Data Key**: \n",
    "- Month: Month that game happened (09-02)\n",
    "- Year: Year that game happened (2019-2024)\n",
    "- Division: (NFC North=1, NFC South=2, NFC East=3, NFC West=4, AFC North=5, AFC South=6, AFC East7, AFC West=8)\n",
    "- Conference: AFC=1, NFC=2\n",
    "- Location: Home=1, Neutral=0, Away=-1\n",
    "- Opp_Wins: # of wins opponent had for entire season\n",
    "- Opp_Loses: # of loses opponent had for entire season\n",
    "- Points: # of points Cheifs or 49ers scored in game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9eb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Needed Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from hyperopt import hp, tpe, Trials\n",
    "\n",
    "\n",
    "#-------------------------------- Inputed Data into Data Frames for model ------------------------------------\n",
    "kc_2019 = {'Month': [9,9,9,9,10,10,10,10,11,11,11,12,12,12,12,12,1,1,2], \n",
    "            'Year': [2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2020,2020,2020],\n",
    "            'Division': [6,8,5,1,6,6,8,1,1,6,8,8,7,8,1,8,6,6,4], \n",
    "            'Conference': [1,1,1,2,1,1,1,2,2,1,1,1,1,1,2,1,1,1,2],\n",
    "            'Location': [-1,-1,1,-1,1,1,-1,1,1,-1,0,1,-1,1,-1,1,1,1,0], \n",
    "            'Opp_Wins': [6,7,14,3,7,10,7,13,10,9,5,7,12,7,8,5,10,9,13],\n",
    "            'Opp_Loses': [10,9,2,12,9,6,9,3,6,7,11,9,4,9,8,11,6,7,3],\n",
    "            'Points': [40,28,33,34,13,24,30,24,26,32,24,40,23,23,26,31,51,35,31]}\n",
    "kc_2019 = pd.DataFrame(kc_2019)\n",
    "\n",
    "kc_2020 = {'Month': [9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,1,1,1,2], \n",
    "            'Year': [2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2021,2021,2021,2021],\n",
    "            'Division': [6,8,5,7,8,7,8,7,2,8,2,8,7,2,2,8,5,7,2], \n",
    "            'Conference': [1,1,1,1,1,1,1,1,2,1,2,1,1,2,2,1,1,1,2],\n",
    "            'Location': [1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,-1,1,1,1,1,0], \n",
    "            'Opp_Wins': [4,7,11,7,8,13,5,2,5,8,11,5,10,12,4,7,11,13,11],\n",
    "            'Opp_Loses': [12,9,5,9,8,3,11,12,11,8,5,11,6,4,12,9,5,3,5],\n",
    "            'Points': [34,23,34,26,32,26,43,35,33,35,27,22,33,32,17,21,22,38,9]}\n",
    "kc_2020 = pd.DataFrame(kc_2020)\n",
    "\n",
    "kc_2021 = {'Month': [9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,1,1,1,1,1], \n",
    "            'Year': [2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2022,2022,2022,2022,2022],\n",
    "            'Division': [5,5,8,3,7,3,6,3,1,8,3,8,8,8,5,5,8,5,7,5], \n",
    "            'Conference': [1,1,1,2,1,2,1,2,2,1,2,1,1,1,1,1,1,1,1,1],\n",
    "            'Location': [1,-1,1,-1,1,-1,-1,1,1,-1,1,1,1,-1,1,-1,-1,1,1,1], \n",
    "            'Opp_Wins': [8,8,9,9,11,7,12,4,13,10,12,7,10,9,9,10,7,9,11,10],\n",
    "            'Opp_Loses': [9,9,8,8,6,10,5,13,4,7,5,10,7,8,7,7,10,7,6,7],\n",
    "            'Points': [33,35,24,42,20,31,3,20,13,41,19,22,48,34,36,31,28,42,42,24]}\n",
    "kc_2021 = pd.DataFrame(kc_2021)\n",
    "\n",
    "kc_2022 = {'Month': [9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,1,1,1,1,2], \n",
    "            'Year': [2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2023,2023,2023,2023,2023],\n",
    "            'Division': [4,8,6,2,8,7,4,6,6,8,4,5,8,6,4,8,8,6,5,3], \n",
    "            'Conference': [2,1,1,2,1,1,2,1,1,1,2,1,1,1,2,1,1,1,1,2],\n",
    "            'Location': [-1,1,-1,-1,1,1,-1,1,1,1,-1,-1,-1,-1,1,1,-1,1,1,0], \n",
    "            'Opp_Wins': [4,10,4,8,6,13,13,7,9,5,10,12,5,3,9,5,6,9,12,14],\n",
    "            'Opp_Loses': [13,7,12,9,11,3,4,10,8,12,7,4,12,13,8,12,11,8,4,3],\n",
    "            'Points': [44,27,17,41,30,20,44,20,27,26,30,24,34,30,24,27,31,27,23,38]}\n",
    "kc_2022 = pd.DataFrame(kc_2022)\n",
    "\n",
    "kc_2023 = {'Month': [9,9,9,10,10,10,10,10,11,11,11,12,12,12,12,12,1,1,1,1], \n",
    "            'Year': [2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2024,2024,2024,2024],\n",
    "            'Division': [1,6,1,7,1,8,8,8,7,3,8,1,7,7,8,5,8,7,7,5], \n",
    "            'Conference': [2,1,2,1,2,1,1,1,1,2,1,2,1,1,1,1,1,1,1,1],\n",
    "            'Location': [1,-1,1,-1,-1,1,1,-1,0,1,-1,-1,1,-1,1,1,-1,1,-1,-1], \n",
    "            'Opp_Wins': [12,9,7,7,7,8,5,8,11,11,8,9,11,4,8,9,5,11,11,13],\n",
    "            'Opp_Loses': [5,8,10,10,10,9,12,9,6,6,9,8,6,13,9,8,12,6,6,4],\n",
    "            'Points': [20,17,41,23,27,19,31,9,21,17,31,19,17,27,14,25,13,26,27,17]}\n",
    "kc_2023 = pd.DataFrame(kc_2023)\n",
    "\n",
    "#-------------------------------- Combined Multipe Data Frames into One Data Frame -----------------------------\n",
    "kc_data = pd.concat([kc_2019, kc_2020, kc_2021, kc_2022, kc_2023])\n",
    "\n",
    "#-------------------------------- Created Super Bowl Prediction Data Frame  ------------------------------------\n",
    "kc_2023_sb = {'Month': [2], \n",
    "            'Year': [2024],\n",
    "            'Division': [4], \n",
    "            'Conference': [2],\n",
    "            'Location': [0], \n",
    "            'Opp_Wins': [12],\n",
    "            'Opp_Loses': [5]}\n",
    "kc_2023_sb = pd.DataFrame(kc_2023_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697bbe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Tuned R^2 Score: -0.12694112782401246\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------- Seperated Independant Variables out from Dataset (X), (y) is the Predictor  ---\n",
    "X = kc_data.drop(['Points'], axis=1)\n",
    "y = kc_data[['Points']]\n",
    "\n",
    "#-------------------------------- Created training and test data  ------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "#-------------------------------- Ran inital model to see baseline R^2 Value  ------------------------------------\n",
    "model = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "predicted_values = model.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = predicted_values\n",
    "\n",
    "r2_score(y_true, y_pred)\n",
    "print('Non-Tuned R^2 Score:', r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397404d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SSE score: -77.83347306640457\n",
      "Best parameters: {'n_estimators': 150, 'max_leaf_nodes': 2, 'max_depth': 9, 'loss': 'squared_error', 'learning_rate': 0.025, 'criterion': 'friedman_mse'}\n"
     ]
    }
   ],
   "source": [
    "# Define parameter space\n",
    "param_space = {'loss':['squared_error', 'absolute_error', 'huber', 'quantile'], \n",
    "              'n_estimators': [150, 300, 1000],\n",
    "              'criterion':['friedman_mse', 'squared_error'],\n",
    "              'learning_rate':[0.025,0.05, 0.1,0.15,0.20,0.25],\n",
    "              'max_depth': [2,3,4,5,6,7,8,9,10],\n",
    "              'max_leaf_nodes':[2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "# Split data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "# Create a custom scoring function for SSE\n",
    "\n",
    "def sse_scorer(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)\n",
    "\n",
    "sse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "\n",
    "\n",
    "# Use RandomizedSearchCV with hyperopt\n",
    "search = RandomizedSearchCV(estimator=model, param_distributions=param_space,\n",
    "                            scoring=sse_scorer, cv=5, n_iter=100, random_state=42)\n",
    "\n",
    "# Perform the search\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Analyze results\n",
    "print(\"Best SSE score:\", search.best_score_)\n",
    "print(\"Best parameters:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b7681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned R^2 Score: -0.02065772852482839\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------- Run Hyper-Tuned model to see if > than baseline R^2 Value  ----------------\n",
    "\n",
    "model = GradientBoostingRegressor(criterion='friedman_mse', learning_rate=0.025,loss='squared_error', \n",
    "                                  max_depth=9, max_leaf_nodes=2, n_estimators=150).fit(X_train, y_train)\n",
    "predicted_values = model.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = predicted_values\n",
    "\n",
    "r2_score(y_true, y_pred)\n",
    "print('Tuned R^2 Score:', r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96ba896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.]\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(criterion='friedman_mse', learning_rate=0.025,loss='squared_error', \n",
    "                                  max_depth=9, max_leaf_nodes=2, n_estimators=150).fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(kc_2023_sb)\n",
    "predictions = np.around(y_pred, decimals=0)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aae9a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature  Importance\n",
      "1        Year    0.385708\n",
      "6   Opp_Loses    0.273538\n",
      "0       Month    0.179910\n",
      "5    Opp_Wins    0.160844\n",
      "2    Division    0.000000\n",
      "3  Conference    0.000000\n",
      "4    Location    0.000000\n"
     ]
    }
   ],
   "source": [
    "# --- Explore how the model weighed the independent variables (X) to predict score (y) --------\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame with original feature names and importances\n",
    "df_importance = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort by importance and display\n",
    "df_importance.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "print(df_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add611ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e5dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Needed Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from hyperopt import hp, tpe, Trials\n",
    "\n",
    "#-------------------------------- Inputed Data into Data Frames for model ------------------------------------\n",
    "\n",
    "sf_2019 = {'Month': [9,9,9,10,10,10,10,10,11,11,11,12,12,12,12,12,1,1,2], \n",
    "            'Year': [2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2020,2020,2020],\n",
    "            'Division': [2,5,5,5,4,3,2,4,4,4,1,5,2,2,4,4,1,1,8], \n",
    "            'Conference': [2,1,1,1,2,2,2,2,2,2,2,1,2,2,2,2,2,2,1],\n",
    "            'Location': [-1,-1,1,1,-1,-1,1,-1,1,1,1,-1,-1,1,1,-1,1,1,0], \n",
    "            'Opp_Wins': [7,2,8,6,9,3,5,5,11,5,13,14,13,7,9,11,10,13,12],\n",
    "            'Opp_Loses': [9,14,8,10,7,13,11,10,5,10,3,2,3,9,7,5,6,3,4],\n",
    "            'Points': [31,41,24,31,20,9,51,28,24,36,37,17,48,22,34,26,27,37,20]}\n",
    "sf_2019 = pd.DataFrame(sf_2019)\n",
    "\n",
    "sf_2020 = {'Month': [9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,1], \n",
    "            'Year': [2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2020,2021],\n",
    "            'Division': [4,7,3,3,7,4,7,4,1,2,4,7,3,3,4,4], \n",
    "            'Conference': [2,1,2,2,1,2,1,2,2,2,2,1,2,2,2,2],\n",
    "            'Location': [1,-1,-1,1,1,1,-1,-1,1,-1,-1,1,1,-1,-1,1], \n",
    "            'Opp_Wins': [8,2,6,4,10,10,7,12,13,12,10,13,7,6,8,12],\n",
    "            'Opp_Loses': [8,14,10,11,6,6,9,4,3,4,6,3,9,10,8,4],\n",
    "            'Points': [20,31,36,20,17,24,33,27,17,13,23,24,15,33,20,23]}\n",
    "sf_2020 = pd.DataFrame(sf_2020)\n",
    "\n",
    "sf_2021 = {'Month': [9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,1,1,1,1,1], \n",
    "            'Year': [2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2022,2022,2022,2022,2022],\n",
    "            'Division': [1,3,1,4,4,6,1,4,4,6,1,4,5,2,6,6,4,3,1,4], \n",
    "            'Conference': [2,2,2,2,2,1,2,2,2,1,2,2,1,2,1,1,2,2,2,2],\n",
    "            'Location': [-1,-1,1,1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,1,-1,-1,-1,-1], \n",
    "            'Opp_Wins': [3,9,13,7,11,12,6,11,12,3,8,7,10,7,12,4,12,12,13,12],\n",
    "            'Opp_Loses': [13,8,4,10,6,5,11,6,5,14,9,10,7,10,5,13,5,5,4,5],\n",
    "            'Points': [41,17,28,21,10,18,33,17,31,30,34,23,26,31,17,23,27,23,13,17]}\n",
    "sf_2021 = pd.DataFrame(sf_2021)\n",
    "\n",
    "sf_2022 = {'Month': [9,9,9,10,10,10,10,10,11,11,11,12,12,12,12,1,1,1,1,1], \n",
    "            'Year': [2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2022,2023,2023,2023,2023,2023],\n",
    "            'Division': [1,4,8,4,2,2,8,4,8,4,2,7,2,4,3,8,4,4,3,3], \n",
    "            'Conference': [2,2,1,2,2,2,1,2,1,2,2,1,2,2,2,1,2,2,2,2],\n",
    "            'Location': [-1,1,-1,1,-1,-1,1,-1,1,0,1,1,1,-1,1,-1,1,1,1,-1], \n",
    "            'Opp_Wins': [3,9,5,5,7,7,14,5,10,4,7,9,8,9,8,6,4,14,12,14],\n",
    "            'Opp_Loses': [14,8,12,12,10,10,3,12,7,13,10,8,9,8,8,11,13,3,5,3],\n",
    "            'Points': [10,27,10,24,37,14,23,31,22,38,13,33,35,21,37,37,38,41,19,7]}\n",
    "sf_2022 = pd.DataFrame(sf_2022)\n",
    "\n",
    "sf_2023 = {'Month': [9,9,9,10,10,10,10,10,11,11,11,12,12,12,12,12,1,1,1], \n",
    "            'Year': [2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2023,2024,2024,2024],\n",
    "            'Division': [5,4,3,4,3,5,1,5,6,2,4,3,4,4,5,3,4,1,1], \n",
    "            'Conference': [1,2,2,2,2,1,2,1,1,2,2,2,2,2,1,2,2,2,2],\n",
    "            'Location': [-1,-1,1,1,1,-1,-1,1,-1,1,-1,-1,1,-1,1,-1,1,1,1], \n",
    "            'Opp_Wins': [10,10,6,4,12,11,7,9,9,9,9,11,9,4,13,4,10,9,12],\n",
    "            'Opp_Loses': [7,7,11,13,5,6,10,8,8,8,8,6,8,13,4,13,7,8,5],\n",
    "            'Points': [30,30,30,35,42,17,17,17,34,27,31,42,28,45,19,27,20,24,34]}\n",
    "sf_2023 = pd.DataFrame(sf_2023)\n",
    "\n",
    "#-------------------------------- Combined Multipe Data Frames into One Data Frame -----------------------------\n",
    "\n",
    "sf_data = pd.concat([sf_2019, sf_2020, sf_2021, sf_2022, sf_2023])\n",
    "\n",
    "#-------------------------------- Created Super Bowl Prediction Data Frame  ------------------------------------\n",
    "\n",
    "sf_2023_sb = {'Month': [2], \n",
    "            'Year': [2024],\n",
    "            'Division': [8], \n",
    "            'Conference': [1],\n",
    "            'Location': [0], \n",
    "            'Opp_Wins': [11],\n",
    "            'Opp_Loses': [6]}\n",
    "sf_2023_sb = pd.DataFrame(sf_2023_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fedd876e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Tuned R^2 Score: -0.7605209864099054\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------- Seperated Independant Variables out from Dataset (X), (y) is the Predictor  ---\n",
    "X = sf_data.drop(['Points'], axis=1)\n",
    "y = sf_data[['Points']]\n",
    "\n",
    "#-------------------------------- Created training and test data  ------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "#-------------------------------- Ran inital model to see baseline R^2 Value  ------------------------------------\n",
    "model = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "predicted_values = model.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = predicted_values\n",
    "\n",
    "r2_score(y_true, y_pred)\n",
    "print('Non-Tuned R^2 Score:', r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539d4447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score SSE: -76.69738712308734\n",
      "Best parameters: {'n_estimators': 100, 'max_leaf_nodes': 2, 'max_depth': 6, 'loss': 'squared_error', 'learning_rate': 0.0075, 'criterion': 'friedman_mse'}\n"
     ]
    }
   ],
   "source": [
    "# Define parameter space\n",
    "param_space = {'loss':['squared_error', 'absolute_error', 'huber', 'quantile'], \n",
    "              'n_estimators': [50,100,200,500,1000],\n",
    "              'criterion':['friedman_mse', 'squared_error'],\n",
    "              'learning_rate':[0.0075, 0.025,0.05,0.1,0.15],\n",
    "              'max_depth': [2,3,4,5,6,7,8,9],\n",
    "              'max_leaf_nodes':[2,3,4,5,6,7,8,9]}\n",
    "\n",
    "# Split data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "# Create a custom scoring function for SSE\n",
    "\n",
    "def sse_scorer(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)\n",
    "\n",
    "sse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "\n",
    "\n",
    "# Use RandomizedSearchCV with hyperopt\n",
    "search = RandomizedSearchCV(estimator=model, param_distributions=param_space,\n",
    "                            scoring=sse_scorer, cv=5, n_iter=100, random_state=42)\n",
    "\n",
    "# Perform the search\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Analyze results\n",
    "print(\"Best score SSE:\", search.best_score_)\n",
    "print(\"Best parameters:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "414004fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned R^2 Score: -0.04900262026798963\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------- Run Hyper-Tuned model to see if > than baseline R^2 Value  ----------------\n",
    "\n",
    "model = GradientBoostingRegressor(criterion='friedman_mse', learning_rate=0.0075,loss='squared_error', \n",
    "                                  max_depth=6, max_leaf_nodes=2, n_estimators=100).fit(X_train, y_train)\n",
    "predicted_values = model.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = predicted_values\n",
    "\n",
    "r2_score(y_true, y_pred)\n",
    "print('Tuned R^2 Score:', r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20a1f855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(sf_2023_sb)\n",
    "predictions = np.around(y_pred, decimals=0)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5374f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature  Importance\n",
      "5    Opp_Wins         1.0\n",
      "0       Month         0.0\n",
      "1        Year         0.0\n",
      "2    Division         0.0\n",
      "3  Conference         0.0\n",
      "4    Location         0.0\n",
      "6   Opp_Loses         0.0\n"
     ]
    }
   ],
   "source": [
    "# --- Explore how the model weighed the independent variables (X) to predict score (y) --------\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame with original feature names and importances\n",
    "df_importance = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort by importance and display\n",
    "df_importance.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "print(df_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
